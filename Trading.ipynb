{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Trading Notebook"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "413adc629dbcd1b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we use the methods established through backtesting to test strategies in real-time simulated markets.\n",
    "\n",
    "First, we import necessary libraries and functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53498a7fbfe54cb2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#   Using requests to grab sentiment data from EODHD and yfinance for scraped yahoo finance data\n",
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "#   Using keras for machine learning models\n",
    "import keras\n",
    "\n",
    "#   Some other important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array, float32, hstack\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T00:05:46.721359Z",
     "start_time": "2024-03-20T00:05:46.717257Z"
    }
   },
   "id": "initial_id",
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we define functions for use in data cleaning, model creation and training, and prediction gathering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "149ad5ce9bb5106b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Download and clean data from multiple sources for a given ticker\n",
    "def get_data(ticker):\n",
    "    hist = yf.Ticker(ticker).history(period=\"5y\")['2021-01-04':]\n",
    "    sentiment = requests.get(f'https://eodhd.com/api/sentiments?s=' + ticker + '&from=2021-01-04&to=' + str(date.today()) + '&api_token=65fa10c8b17a55.92906995&fmt=json').json()\n",
    "    sentiments = pd.Series(sentiment[ticker + '.US'][i]['normalized'] for i in range(len(sentiment[ticker + '.US'])))\n",
    "    dates = pd.Series(datetime.strptime(sentiment[ticker + '.US'][i]['date'], \"%Y-%m-%d\") for i in range(len(sentiment[ticker + '.US'])))\n",
    "    sentiment_df = pd.concat([dates, sentiments], axis=1)\n",
    "    sentiment_df.set_index(0, inplace=True)\n",
    "    hist = hist.tz_localize(None)\n",
    "    sentiment_df.join(hist)\n",
    "    hist = hist.merge(sentiment_df, left_index=True, right_index=True)\n",
    "    hist = hist.iloc[:, [0, 1, 2, 3, 4, 7]].rename(columns={1: 'Sentiment'})\n",
    "    return hist\n",
    "\n",
    "# Download and clean data from multiple sources for a given ticker for model training\n",
    "def get_training_data(ticker):\n",
    "    hist = yf.Ticker(ticker).history(period=\"5y\")['2021-01-04':]\n",
    "    sentiment = requests.get(f'https://eodhd.com/api/sentiments?s=' + ticker + '&from=2021-01-04&to=' + str(date.today()) + '&api_token=65fa10c8b17a55.92906995&fmt=json').json()\n",
    "    sentiments = pd.Series(sentiment[ticker + '.US'][i]['normalized'] for i in range(len(sentiment[ticker + '.US'])))\n",
    "    dates = pd.Series(datetime.strptime(sentiment[ticker + '.US'][i]['date'], \"%Y-%m-%d\") for i in range(len(sentiment[ticker + '.US'])))\n",
    "    sentiment_df = pd.concat([dates, sentiments], axis=1)\n",
    "    sentiment_df.set_index(0, inplace=True)\n",
    "    hist = hist.tz_localize(None)\n",
    "    sentiment_df.join(hist)\n",
    "    hist = hist.merge(sentiment_df, left_index=True, right_index=True)\n",
    "    hist = hist.iloc[:, [0, 1, 2, 3, 4, 7]].rename(columns={1: 'Sentiment'})\n",
    "    hist['Target'] = hist['Close'].shift(-1)\n",
    "    hist = hist.iloc[:-5]\n",
    "    upList, downList = list(), list()\n",
    "    for i in range(len(hist)):\n",
    "        if hist.iloc[i, 6] >= hist.iloc[i, 2] * 1.004:\n",
    "            upList.append(1)\n",
    "        else:\n",
    "            upList.append(0)\n",
    "        if hist.iloc[i, 6] <= hist.iloc[i, 2] * 0.996:\n",
    "            downList.append(1)\n",
    "        else:\n",
    "            downList.append(0)\n",
    "    hist = hist.drop('Target', axis=1)\n",
    "    hist['Up'], hist['Down'] = upList, downList\n",
    "    return hist\n",
    "\n",
    "# Available Training Data: historical prices, historical sentiment data\n",
    "def define_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(5, 2)))\n",
    "    model.add(keras.layers.LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(keras.layers.LSTM(100, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(50))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    x, y = list(), list()\n",
    "    for i in range(0, len(sequences) - n_steps, n_steps):\n",
    "        x.append(sequences[i:i + n_steps, :-1])\n",
    "        y.append(sequences[i+n_steps-1, -1])\n",
    "    return array(x).astype(float32), array(y).astype(float32)\n",
    "\n",
    "def train_models(ticker):\n",
    "    df = get_training_data(ticker)\n",
    "\n",
    "    in_seq1 = df.iloc[:, 3].to_numpy().reshape((len(df), 1))\n",
    "    in_seq2 = df.iloc[:, 5].to_numpy().reshape((len(df), 1))\n",
    "    out_seq_up = df.iloc[:, 6].to_numpy().reshape((len(df), 1))\n",
    "    out_seq_down = df.iloc[:, 7].to_numpy().reshape((len(df), 1))\n",
    "\n",
    "    model_up, model_down = define_model(), define_model()\n",
    "\n",
    "    x, y = split_sequences(hstack((in_seq1, in_seq2, out_seq_up)), 9)\n",
    "    model_up.fit(x, y, verbose=False, epochs=200)\n",
    "\n",
    "    x, y = split_sequences(hstack((in_seq1, in_seq2, out_seq_down)), 9)\n",
    "    model_down.fit(x, y, verbose=False, epochs=200)\n",
    "    \n",
    "    return model_up, model_down\n",
    "\n",
    "# returns a prediction direction and strength (one float) that correspond to a forecast\n",
    "def prediction(data, model_up, model_down):\n",
    "    # Grab the base predictions for the model\n",
    "    pos = data.index.get_loc('2024-03-11')\n",
    "    input = array(data.iloc[pos-8:pos+1, [3, 5]]).reshape((1, 9, 2)).astype(float32)\n",
    "    up_base = model_up.predict(input, verbose=False)\n",
    "    down_base = model_down.predict(input, verbose=False)\n",
    "\n",
    "    input = array(data.iloc[-9:, [3, 5]]).reshape((1, 9, 2)).astype(float32)\n",
    "    up_chance = model_up.predict(input, verbose=False)\n",
    "    down_chance = model_down.predict(input, verbose=False)\n",
    "\n",
    "    if up_chance > up_base * 0.2 and up_chance > down_chance:\n",
    "        forecast = (up_chance - up_base)/up_base\n",
    "    elif down_chance > down_base * 0.2 and down_chance > up_chance + 0.2:\n",
    "        forecast = -(down_chance - down_base)/down_base\n",
    "    else:\n",
    "        forecast = 0\n",
    "    \n",
    "    return forecast[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T23:51:07.234171Z",
     "start_time": "2024-03-19T23:51:07.210873Z"
    }
   },
   "id": "d4ff2a5adf1ed90f",
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, if we have not already, we can train models on our gathered and cleaned data and save the models for later use"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9d567fc46fa3698"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train models for every stock from this list of tickers\n",
    "ticker_list = ['AAPL', 'PG', 'JNJ', 'PEP', 'WMT', 'KO', 'MCD', 'GE']\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    # Train the models on the most up-to-date data\n",
    "    model_up, model_down = train_models(ticker)\n",
    "    \n",
    "    # Save the models to the folder so their baselines are consistent\n",
    "    model_up.save(r'C:\\Users\\shell\\dataSpell\\ml-backtesting\\models (DO NOT TOUCH)/' + ticker + '_UP.keras')\n",
    "    model_down.save(r'C:\\Users\\shell\\dataSpell\\ml-backtesting\\models (DO NOT TOUCH)/'+ ticker + '_DOWN.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T23:46:06.028142Z",
     "start_time": "2024-03-19T23:42:34.312049Z"
    }
   },
   "id": "e44ff08b1c7d63c0",
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can use the models and most up-to-date data to generate forecasts for use in a midterm investment strategy. We intentionally do not retrain the models for two reasons: we use a baseline prediction in determining forecasts, so retraining the models could alter the baseline prediction; models were not retrained during backtesting, so not retraining models is more consistent with previous backtests."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5239048678ff1d1a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Forecast\nAAPL  0.069919\nPG    0.129365\nJNJ  -0.136992\nPEP   0.075050\nWMT  -0.001690\nKO    0.009319\nMCD  -0.212278\nGE   -0.003461",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Forecast</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AAPL</th>\n      <td>0.069919</td>\n    </tr>\n    <tr>\n      <th>PG</th>\n      <td>0.129365</td>\n    </tr>\n    <tr>\n      <th>JNJ</th>\n      <td>-0.136992</td>\n    </tr>\n    <tr>\n      <th>PEP</th>\n      <td>0.075050</td>\n    </tr>\n    <tr>\n      <th>WMT</th>\n      <td>-0.001690</td>\n    </tr>\n    <tr>\n      <th>KO</th>\n      <td>0.009319</td>\n    </tr>\n    <tr>\n      <th>MCD</th>\n      <td>-0.212278</td>\n    </tr>\n    <tr>\n      <th>GE</th>\n      <td>-0.003461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a forecast for every stock on this list\n",
    "ticker_list = ['AAPL', 'PG', 'JNJ', 'PEP', 'WMT', 'KO', 'MCD', 'GE']\n",
    "\n",
    "# Store the forecasts in a dataframe\n",
    "forecasts = pd.DataFrame(index=ticker_list)\n",
    "forecasts['Forecast'] = [0.0] * len(ticker_list)\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    # Grab the models from the model folder\n",
    "    model_up = keras.models.load_model(r'C:\\Users\\shell\\dataSpell\\ml-backtesting\\models (DO NOT TOUCH)/'+ ticker + '_UP.keras')\n",
    "    model_down = keras.models.load_model(r'C:\\Users\\shell\\dataSpell\\ml-backtesting\\models (DO NOT TOUCH)/'+ ticker + '_DOWN.keras')\n",
    "    \n",
    "    # Add the results to the dataframe\n",
    "    forecasts.loc[ticker] = [prediction(get_data(ticker), model_up, model_down)]\n",
    "\n",
    "# Display the forecasts for each ticker in the list\n",
    "display(forecasts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T00:03:20.176936Z",
     "start_time": "2024-03-20T00:03:00.802771Z"
    }
   },
   "id": "10ef4c3ce4510d47",
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can use these forecasts on stock direction as a factor in a midterm investment strategy. As is evident through backtesting, relying on forecasts alone can be profitable at times but can lead to massive losses when obvious external factors (such as earnings) are ignored."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86a7b7bbc9662da5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: get the API data to remind me NOT to trade on earnings days (liquidate everything for that stock days in advance, even at a loss)\n",
    "TODO: automatically add forecasts to an automatically displayed forecast history each time we make new predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5f50e5ef6d8d44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
